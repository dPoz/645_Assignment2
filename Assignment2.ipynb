{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dc17d8-f4ac-4cf2-b38f-3e71a629d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torchvision\n",
    "from torchvision import datasets as ds, transforms, models \n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torchvision.models import resnet18, mobilenet_v2, MobileNet_V2_Weights\n",
    "from transformers import DistilBertModel, DistilBertTokenizer, AdamW, AutoProcessor, get_scheduler, AutoModelForCausalLM, AutoTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "\n",
    "# import sys\n",
    "# sys.path.append('/home/poz/Notebooks/645_Assignment2')\n",
    "# from myDefsnClasses import imshow, DistilBERTClassifier, read_text_files_with_labels, train, evaluate, predict, MultiInputModel, MultiModalDataset, fullTrain\n",
    "\n",
    "# import multiprocessing\n",
    "# if __name__ == \"__main__\":\n",
    "#     multiprocessing.set_start_method(\"fork\")\n",
    "#     torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import ImageOps, Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "import re\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = \"0\"\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "print('CUDA available', torch.cuda.is_available())\n",
    "print('CUDA version', torch.version.cuda)\n",
    "print('cuDNN enabled', torch.backends.cudnn.enabled)\n",
    "print('cuDNN version', torch.backends.cudnn.version())\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Torchvision version:\", torchvision.__version__)\n",
    "\n",
    "n_cuda_devices = torch.cuda.device_count()\n",
    "for i in range(n_cuda_devices):\n",
    "  print(f'Device {i} name:', torch.cuda.get_device_name(i))\n",
    "\n",
    "batch_size = 32\n",
    "image_resize = 224\n",
    "num_workers = 8\n",
    "num_epochs = 10\n",
    "max_len = 24\n",
    "best_loss = 1e+10\n",
    "learning_rate = 2e-5\n",
    "stats = (torch.tensor([0.4482, 0.4192, 0.3900]), torch.tensor([0.2918, 0.2796, 0.2709]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715d148a-6571-4a8d-bf38-fe454604bfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the imshow function to ensure stats are on the same device as the image\n",
    "def imshow(img, stats):\n",
    "    mean = stats[0].view(3, 1, 1).to(img.device)\n",
    "    std = stats[1].view(3, 1, 1).to(img.device)\n",
    "    img = img * std + mean\n",
    "    npimg = img.cpu().numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Define the text model\n",
    "class DistilBERTClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DistilBERTClassifier, self).__init__()\n",
    "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.out = nn.Linear(self.distilbert.config.hidden_size, num_classes)\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        pooled_output = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        output = self.drop(pooled_output[:,0])\n",
    "        return self.out(output)\n",
    "\n",
    "# Extract text from file names as well as labels\n",
    "def read_text_files_with_labels(path):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    class_folders = sorted(os.listdir(path))\n",
    "    label_map = {class_name: idx for idx, class_name in enumerate(class_folders)}\n",
    "    for class_name in class_folders:\n",
    "        class_path = os.path.join(path, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            file_names = os.listdir(class_path)\n",
    "            for file_name in file_names:\n",
    "                file_path = os.path.join(class_path, file_name)\n",
    "                if os.path.isfile(file_path):\n",
    "                    file_name_no_ext, _ = os.path.splitext(file_name)\n",
    "                    text = file_name_no_ext.replace('_', ' ')\n",
    "                    text_without_digits = re.sub(r'\\d+', '', text)\n",
    "                    texts.append(text_without_digits)\n",
    "                    labels.append(label_map[class_name])\n",
    "    return np.array(texts), np.array(labels)\n",
    "\n",
    "# Define training function\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        images = batch['image'].to(device)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images, input_ids, attention_mask)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            images = batch['image'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            output = model(images, input_ids, attention_mask)\n",
    "            loss = criterion(output, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, preds = torch.max(output, 1)\n",
    "            correct += torch.sum(preds == labels).item()\n",
    "            total += labels.size(0)\n",
    "    accuracy = 100*correct / total\n",
    "    return total_loss / len(dataloader), accuracy\n",
    "\n",
    "def predict(model, dataloader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    predictions = []\n",
    "    with torch.no_grad():  # Disable gradient tracking\n",
    "        for batch in dataloader:\n",
    "            images = batch['image'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(images, input_ids, attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "    return predictions\n",
    "\n",
    "class MultiInputModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultiInputModel, self).__init__()\n",
    "        # Image model\n",
    "        self.image_model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n",
    "        num_features = self.image_model.classifier[1].in_features\n",
    "        self.image_model.classifier[1] = nn.Identity()\n",
    "        # Adding additional convolutional and pooling layers to image model\n",
    "        self.conv1 = nn.Conv2d(in_channels=num_features, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        # Text model\n",
    "        self.text_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.text_fc = nn.Linear(self.text_model.config.hidden_size, 768)\n",
    "        # Combining both image and text features\n",
    "        self.fc1 = nn.Linear(1024, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 16)\n",
    "        self.fc4 = nn.Linear(16, num_classes)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        # Set requires_grad = True for all parameters in MobileNetV2 and DistilBERT to fine-tune them\n",
    "        for param in self.image_model.parameters():\n",
    "            param.requires_grad = True  # Allow training of image model\n",
    "        for param in self.text_model.parameters():\n",
    "            param.requires_grad = True  # Allow training of text model\n",
    "    def forward(self, image, input_ids, attention_mask):\n",
    "        # Image features\n",
    "        image_features = self.image_model.features(image)\n",
    "        image_features = self.pool1(F.relu(self.conv1(image_features)))\n",
    "        image_features = self.pool2(F.relu(self.conv2(image_features)))\n",
    "        image_features = image_features.mean([2, 3])  # Global Average Pooling\n",
    "        # Text features\n",
    "        text_features = self.text_model(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        text_features = text_features[:, 0, :]  # Use [CLS] token for classification\n",
    "        text_features = self.text_fc(text_features)\n",
    "        # Combine image and text features\n",
    "        combined_features = torch.cat((image_features, text_features), dim=1)\n",
    "        # Classifier with Activation functions, and Dropout\n",
    "        x = self.fc1(combined_features)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "class MultiModalDataset(Dataset):\n",
    "    def __init__(self, image_dataset, texts, labels, tokenizer, max_len):\n",
    "        self.image_dataset = image_dataset\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    def __len__(self):\n",
    "        return len(self.image_dataset)\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.image_dataset[idx]\n",
    "        label = self.labels[idx]\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'image': image,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def predictALL(model, dataloader, device, class_names):\n",
    "    correct_pred = {classname: 0 for classname in class_names}\n",
    "    total_pred = {classname: 0 for classname in class_names}\n",
    "    model.eval()\n",
    "    showFirstTenMissClassed = -1\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            images = batch['image'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            outputs = model(images, input_ids, attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            for label, prediction, image in zip(labels, preds, images):\n",
    "                if label == prediction:\n",
    "                    correct_pred[class_names[label]] += 1\n",
    "                if label != prediction:\n",
    "                    if showFirstTenMissClassed >= 0:\n",
    "                        print(f\"This is classed as: {class_names[label]}\\nThe model predicted class: {class_names[prediction]}\")\n",
    "                        imshow(image, stats)\n",
    "                        showFirstTenMissClassed -= 1\n",
    "                total_pred[class_names[label]] += 1\n",
    "    test_accuracy = 100-(100*(sum(total_pred.values())-sum(correct_pred.values()))/sum(total_pred.values()))\n",
    "    print(f'Test accuracy for all classes: {test_accuracy:.2f}%')\n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        print(f'Accuracy for class: {classname:5s} is {accuracy:.2f}%')\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4a3666-8e5d-40d6-aece-3af183802cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.Resize((232, 232), interpolation=InterpolationMode.BILINEAR),\n",
    "        transforms.RandomCrop(image_resize),\n",
    "        transforms.Resize((image_resize, image_resize)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize((image_resize, image_resize)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    \"test\": transforms.Compose([\n",
    "        transforms.Resize((image_resize, image_resize)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = r\"/home/poz/garbage_data\"\n",
    "train_dir = os.path.join(data_dir, \"CVPR_2024_dataset_Train\")\n",
    "val_dir = os.path.join(data_dir, \"CVPR_2024_dataset_Val\")\n",
    "test_dir = os.path.join(data_dir, \"CVPR_2024_dataset_Test\")\n",
    "\n",
    "text_train, labels_train = read_text_files_with_labels(train_dir)\n",
    "text_val, labels_val = read_text_files_with_labels(val_dir)\n",
    "text_test, labels_test = read_text_files_with_labels(test_dir)\n",
    "\n",
    "datasets = {\"train\": ds.ImageFolder(train_dir, transform=transform[\"train\"]),\n",
    "            \"val\": ds.ImageFolder(val_dir, transform=transform[\"val\"]),\n",
    "            \"test\": ds.ImageFolder(test_dir, transform=transform[\"test\"])}\n",
    "\n",
    "class_names = datasets['train'].classes\n",
    "print(class_names)\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "datasets = {\"train\": MultiModalDataset(datasets['train'], text_train, labels_train, tokenizer, max_len),\n",
    "            \"val\": MultiModalDataset(datasets['val'], text_val, labels_val, tokenizer, max_len),\n",
    "            \"test\": MultiModalDataset(datasets['test'], text_test, labels_test, tokenizer, max_len)}\n",
    "\n",
    "dataloaders = {\"train\": DataLoader(datasets[\"train\"], batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True),\n",
    "               \"val\": DataLoader(datasets[\"val\"], batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True),\n",
    "               \"test\": DataLoader(datasets[\"test\"], batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)}\n",
    "\n",
    "print(\"Train set:\", len(dataloaders['train'])*batch_size)\n",
    "print(\"Val set:\", len(dataloaders['val'])*batch_size)\n",
    "print(\"Test set:\", len(dataloaders['test'])*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d552eb0-271a-4c2c-a74d-fde23c68bb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiInputModel(num_classes=len(class_names)).to(device)\n",
    "\n",
    "# Training parameters\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-10)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be412b1-81ba-4500-ba8c-dd0a124dee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "best_val_accuracy = 0\n",
    "best_test_accuracy = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nStarted Training Loop =\", datetime.now().strftime(f\"%H:%M:%S\"))\n",
    "    train_loss = train(model, dataloaders['train'], optimizer, criterion, device)\n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {train_loss:.4f}\\n')\n",
    "    print(f\"Started Validaiton Loop =\", datetime.now().strftime(f\"%H:%M:%S\"))\n",
    "    val_loss, val_accuracy = evaluate(model, dataloaders['val'], criterion, device)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "    print(f\"\\nStarted Calculating Test Accuracy =\", datetime.now().strftime(f\"%H:%M:%S\"))\n",
    "    test_accuracy = predictALL(model, dataloaders['test'], device, class_names)\n",
    "    if val_loss >= best_loss*1.25 or val_accuracy <= best_val_accuracy*0.98-7 or test_accuracy <= best_test_accuracy*0.98-7 :\n",
    "        print(f\"\\nValidation error grew by 25% ,or validation accuracy dropped by 2=3%, or test accuracy dropped by 2=3%, so stopped training.\")\n",
    "        break\n",
    "    if val_loss <= best_loss or best_val_accuracy <= val_accuracy:\n",
    "        best_loss = val_loss\n",
    "        best_val_accuracy = val_accuracy\n",
    "    if best_test_accuracy <= test_accuracy:\n",
    "        best_test_accuracy = test_accuracy\n",
    "        torch.save(model.state_dict(), f'best_model.pth')\n",
    "        print(f\"\\nThe model has been saved!\")\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4929eccd-864d-4caf-ab9d-307b85195eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "# Evaluation\n",
    "test_predictions = np.array(predict(model, dataloaders['test'], device))\n",
    "print(f\"Accuracy: {(test_predictions == labels_test).sum()/len(labels_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aec7e8-1939-4fd2-b590-c5c2f805550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = predictALL(model, dataloaders['test'], device, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0646f7f-7a76-4a78-b705-f7bfebea86e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(labels_test, test_predictions)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', cbar=False)\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f709f3f-9767-493d-9a2a-9e261cac44ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
