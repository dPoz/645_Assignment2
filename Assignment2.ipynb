{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7dc17d8-f4ac-4cf2-b38f-3e71a629d498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available True\n",
      "CUDA version 12.4\n",
      "cuDNN enabled True\n",
      "cuDNN version 90100\n",
      "PyTorch version: 2.6.0+cu124\n",
      "Torchvision version: 0.21.0+cu124\n",
      "Device 0 name: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torchvision\n",
    "from torchvision import datasets as ds, transforms, models \n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torchvision.models import resnet18, mobilenet_v2, MobileNet_V2_Weights\n",
    "from transformers import DistilBertModel, DistilBertTokenizer, AdamW, AutoProcessor, get_scheduler, AutoModelForCausalLM, AutoTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import ImageOps, Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "import re\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = \"0\"\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "print('CUDA available', torch.cuda.is_available())\n",
    "print('CUDA version', torch.version.cuda)\n",
    "print('cuDNN enabled', torch.backends.cudnn.enabled)\n",
    "print('cuDNN version', torch.backends.cudnn.version())\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Torchvision version:\", torchvision.__version__)\n",
    "\n",
    "n_cuda_devices = torch.cuda.device_count()\n",
    "for i in range(n_cuda_devices):\n",
    "  print(f'Device {i} name:', torch.cuda.get_device_name(i))\n",
    "\n",
    "batch_size = 32\n",
    "image_resize = 224\n",
    "num_workers = 8\n",
    "num_epochs = 20\n",
    "max_len = 24\n",
    "learning_rate = 2e-5\n",
    "stats = (torch.tensor([0.4482, 0.4192, 0.3900]), torch.tensor([0.2918, 0.2796, 0.2709]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f24e054-eab6-48d6-9c53-161a7e20b0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modify the imshow function to ensure stats are on the same device as the image\n",
    "def imshow(img, stats):\n",
    "    mean = stats[0].view(3, 1, 1).to(img.device)\n",
    "    std = stats[1].view(3, 1, 1).to(img.device)\n",
    "    img = img * std + mean\n",
    "    npimg = img.cpu().numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Extract text from file names as well as labels\n",
    "def read_text_files_with_labels(path):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    class_folders = sorted(os.listdir(path))\n",
    "    label_map = {class_name: idx for idx, class_name in enumerate(class_folders)}\n",
    "    for class_name in class_folders:\n",
    "        class_path = os.path.join(path, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            file_names = os.listdir(class_path)\n",
    "            for file_name in file_names:\n",
    "                file_path = os.path.join(class_path, file_name)\n",
    "                if os.path.isfile(file_path):\n",
    "                    file_name_no_ext, _ = os.path.splitext(file_name)\n",
    "                    text = file_name_no_ext.replace('_', ' ')\n",
    "                    text_without_digits = re.sub(r'\\d+', '', text)\n",
    "                    texts.append(text_without_digits)\n",
    "                    labels.append(label_map[class_name])\n",
    "    return np.array(texts), np.array(labels)\n",
    "\n",
    "class MultiModalDataset(Dataset):\n",
    "    def __init__(self, image_dataset, texts, labels, tokenizer, max_len):\n",
    "        self.image_dataset = image_dataset\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    def __len__(self):\n",
    "        return len(self.image_dataset)\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.image_dataset[idx]\n",
    "        label = self.labels[idx]\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'image': image,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9686af86-484b-452b-89c6-99283972db7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training function\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        images = batch['image'].to(device)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images, input_ids, attention_mask)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "    \n",
    "# Define evaluation function\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Validating\"):\n",
    "            images = batch['image'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            output = model(images, input_ids, attention_mask)\n",
    "            loss = criterion(output, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, preds = torch.max(output, 1)\n",
    "            total_correct += torch.sum(preds == labels).item()\n",
    "            total_samples += labels.size(0)\n",
    "    accuracy = 100*total_correct / total_samples\n",
    "    return total_loss / len(dataloader), accuracy\n",
    "\n",
    "def predict(model, dataloader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    predictions = []\n",
    "    with torch.no_grad():  # Disable gradient tracking\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            images = batch['image'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(images, input_ids, attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "    return predictions\n",
    "\n",
    "def predictALL(model, dataloader, device, class_names):\n",
    "    correct_pred = {classname: 0 for classname in class_names}\n",
    "    total_pred = {classname: 0 for classname in class_names}\n",
    "    model.eval()\n",
    "    showFirstTenMissClassed = -1\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            images = batch['image'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            outputs = model(images, input_ids, attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            for label, prediction, image in zip(labels, preds, images):\n",
    "                if label == prediction:\n",
    "                    correct_pred[class_names[label]] += 1\n",
    "                if label != prediction:\n",
    "                    if showFirstTenMissClassed >= 0:\n",
    "                        print(f\"This is classed as: {class_names[label]}\\nThe model predicted class: {class_names[prediction]}\")\n",
    "                        imshow(image, stats)\n",
    "                        showFirstTenMissClassed -= 1\n",
    "                total_pred[class_names[label]] += 1\n",
    "    test_accuracy = 100-(100*(sum(total_pred.values())-sum(correct_pred.values()))/sum(total_pred.values()))\n",
    "    print(f'Accuracy for all classes: {test_accuracy:.2f}%')\n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        print(f'Accuracy for class: {classname:5s} is {accuracy:.2f}%, class size: {total_pred[classname]:.0f}')\n",
    "    return test_accuracy\n",
    "\n",
    "def epochLoop(model, dataloaders, optimizer, criterion, device, class_names, num_epochs):\n",
    "    best_loss = float('inf')\n",
    "    best_val_accuracy = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nStarted Training Loop =\", datetime.now().strftime(f\"%H:%M:%S\"))\n",
    "        train_loss = train(model, dataloaders['train'], optimizer, criterion, device)\n",
    "        print(f\"Started Validaiton Loop =\", datetime.now().strftime(f\"%H:%M:%S\"))\n",
    "        val_loss, val_accuracy = evaluate(model, dataloaders['val'], criterion, device)\n",
    "        print(f'\\nEpoch {epoch + 1}/{num_epochs}')\n",
    "        print(f'Train Loss: {train_loss:.4f}')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\\n')\n",
    "        if val_loss >= best_loss*1.5 or val_accuracy <= best_val_accuracy*0.96:\n",
    "            print(f\"Validation error grew by 50%, or validation accuracy dropped by 4%, so stopped training.\")\n",
    "            break\n",
    "        if val_loss <= best_loss or best_val_accuracy <= val_accuracy:\n",
    "            torch.save(model.state_dict(), f'best_model.pth')\n",
    "            print(f\"The model has been saved!\")\n",
    "            if val_loss <= best_loss:\n",
    "                best_loss = val_loss\n",
    "                print(f\"Due to lowest validation loss.\")\n",
    "            if best_val_accuracy <= val_accuracy:\n",
    "                best_val_accuracy = val_accuracy\n",
    "                print(f\"Due to highest validation accuracy.\")\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a93c7637-cab2-41c4-b9cc-41f1973a2004",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiInputModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultiInputModel, self).__init__()\n",
    "        # Image model\n",
    "        self.image_model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n",
    "        num_features = self.image_model.classifier[1].in_features\n",
    "        self.image_model.classifier[1] = nn.Identity()\n",
    "        # Adding additional convolutional and pooling layers to image model\n",
    "        self.conv1 = nn.Conv2d(in_channels=num_features, out_channels=1024, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        # Text model\n",
    "        self.text_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.text_fc = nn.Linear(self.text_model.config.hidden_size, 768)\n",
    "        # Combining both image and text features\n",
    "        self.fc1 = nn.Linear(1280, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 16)\n",
    "        self.fc4 = nn.Linear(16, num_classes)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(512)\n",
    "        # Set requires_grad = True for all parameters in MobileNetV2 and DistilBERT to fine-tune them\n",
    "        for param in self.image_model.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.text_model.parameters():\n",
    "            param.requires_grad = True\n",
    "    def forward(self, image, input_ids, attention_mask):\n",
    "        # Image features\n",
    "        image_features = self.image_model.features(image)\n",
    "        image_features = self.pool1(F.relu(self.conv1(image_features)))\n",
    "        image_features = self.pool2(F.relu(self.conv2(image_features)))\n",
    "        image_features = image_features.mean([2, 3])  # Global Average Pooling\n",
    "        # Text features\n",
    "        text_features = self.text_model(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        text_features = text_features[:, 0, :]  # Use [CLS] token for classification\n",
    "        text_features = self.text_fc(text_features)\n",
    "        # Combine image and text features\n",
    "        combined_features = torch.cat((image_features, text_features), dim=1)\n",
    "        # Classifier with Activation functions, and Dropout\n",
    "        combined_features = self.fc1(combined_features)\n",
    "        combined_features = F.relu(combined_features)\n",
    "        combined_features = self.dropout(combined_features)\n",
    "        combined_features = self.batch_norm1(combined_features)\n",
    "        combined_features = self.fc2(combined_features)\n",
    "        combined_features = F.relu(combined_features)\n",
    "        combined_features = self.dropout(combined_features)\n",
    "        combined_features = self.fc3(combined_features)\n",
    "        combined_features = F.relu(combined_features)\n",
    "        combined_features = self.dropout(combined_features)\n",
    "        combined_features = self.fc4(combined_features)\n",
    "        return combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d4a3666-8e5d-40d6-aece-3af183802cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Black', 'Blue', 'Green', 'TTR']\n",
      "Train set: 11648\n",
      "Val set: 1824\n",
      "Test set: 3456\n"
     ]
    }
   ],
   "source": [
    "transform = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.Resize((232, 232), interpolation=InterpolationMode.BILINEAR),\n",
    "        transforms.RandomCrop(image_resize),\n",
    "        transforms.Resize((image_resize, image_resize)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize((image_resize, image_resize)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    \"test\": transforms.Compose([\n",
    "        transforms.Resize((image_resize, image_resize)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = r\"/home/poz/garbage_data\"\n",
    "train_dir = os.path.join(data_dir, \"CVPR_2024_dataset_Train\")\n",
    "val_dir = os.path.join(data_dir, \"CVPR_2024_dataset_Val\")\n",
    "test_dir = os.path.join(data_dir, \"CVPR_2024_dataset_Test\")\n",
    "\n",
    "text_train, labels_train = read_text_files_with_labels(train_dir)\n",
    "text_val, labels_val = read_text_files_with_labels(val_dir)\n",
    "text_test, labels_test = read_text_files_with_labels(test_dir)\n",
    "\n",
    "datasets = {\"train\": ds.ImageFolder(train_dir, transform=transform[\"train\"]),\n",
    "            \"val\": ds.ImageFolder(val_dir, transform=transform[\"val\"]),\n",
    "            \"test\": ds.ImageFolder(test_dir, transform=transform[\"test\"])}\n",
    "\n",
    "class_names = datasets['train'].classes\n",
    "num_classes=len(class_names)\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "datasets = {\"train\": MultiModalDataset(datasets['train'], text_train, labels_train, tokenizer, max_len),\n",
    "            \"val\": MultiModalDataset(datasets['val'], text_val, labels_val, tokenizer, max_len),\n",
    "            \"test\": MultiModalDataset(datasets['test'], text_test, labels_test, tokenizer, max_len)}\n",
    "\n",
    "dataloaders = {\"train\": DataLoader(datasets[\"train\"], batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True),\n",
    "               \"val\": DataLoader(datasets[\"val\"], batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True),\n",
    "               \"test\": DataLoader(datasets[\"test\"], batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)}\n",
    "\n",
    "print(class_names)\n",
    "print(\"Train set:\", len(dataloaders['train'])*batch_size)\n",
    "print(\"Val set:\", len(dataloaders['val'])*batch_size)\n",
    "print(\"Test set:\", len(dataloaders['test'])*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0ff37e8-2f3e-4463-8fb3-2da0c0803dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiInputModel(num_classes).to(device)\n",
    "\n",
    "# Training parameters\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-10)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e3d8f48-3432-4f82-9871-d7aa7954e601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Started Training Loop = 17:52:15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 364/364 [01:20<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Validaiton Loop = 17:53:35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 57/57 [00:08<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "Train Loss: 0.8223\n",
      "Val Loss: 0.4469, Val Accuracy: 89.11%\n",
      "\n",
      "The model has been saved!\n",
      "Due to lowest validation loss.\n",
      "Due to highest validation accuracy.\n",
      "\n",
      "Started Training Loop = 17:53:44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 364/364 [01:15<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Validaiton Loop = 17:55:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 57/57 [00:08<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/20\n",
      "Train Loss: 0.3782\n",
      "Val Loss: 0.2632, Val Accuracy: 92.11%\n",
      "\n",
      "The model has been saved!\n",
      "Due to lowest validation loss.\n",
      "Due to highest validation accuracy.\n",
      "\n",
      "Started Training Loop = 17:55:09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 364/364 [01:16<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Validaiton Loop = 17:56:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 57/57 [00:08<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/20\n",
      "Train Loss: 0.2326\n",
      "Val Loss: 0.2101, Val Accuracy: 93.78%\n",
      "\n",
      "The model has been saved!\n",
      "Due to lowest validation loss.\n",
      "Due to highest validation accuracy.\n",
      "\n",
      "Started Training Loop = 17:56:34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 364/364 [01:17<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Validaiton Loop = 17:57:52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 57/57 [00:08<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/20\n",
      "Train Loss: 0.1648\n",
      "Val Loss: 0.2045, Val Accuracy: 93.11%\n",
      "\n",
      "The model has been saved!\n",
      "Due to lowest validation loss.\n",
      "\n",
      "Started Training Loop = 17:58:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 364/364 [01:17<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Validaiton Loop = 17:59:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 57/57 [00:08<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/20\n",
      "Train Loss: 0.1211\n",
      "Val Loss: 0.1974, Val Accuracy: 93.72%\n",
      "\n",
      "The model has been saved!\n",
      "Due to lowest validation loss.\n",
      "\n",
      "Started Training Loop = 17:59:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 364/364 [01:18<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Validaiton Loop = 18:00:46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 57/57 [00:07<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/20\n",
      "Train Loss: 0.0966\n",
      "Val Loss: 0.2482, Val Accuracy: 92.61%\n",
      "\n",
      "\n",
      "Started Training Loop = 18:00:54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 364/364 [01:17<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Validaiton Loop = 18:02:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 57/57 [00:08<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/20\n",
      "Train Loss: 0.0798\n",
      "Val Loss: 0.2198, Val Accuracy: 93.83%\n",
      "\n",
      "The model has been saved!\n",
      "Due to highest validation accuracy.\n",
      "\n",
      "Started Training Loop = 18:02:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 364/364 [01:21<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Validaiton Loop = 18:03:43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 57/57 [00:07<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/20\n",
      "Train Loss: 0.0672\n",
      "Val Loss: 0.2318, Val Accuracy: 93.56%\n",
      "\n",
      "\n",
      "Started Training Loop = 18:03:51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 364/364 [01:23<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Validaiton Loop = 18:05:14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 57/57 [00:08<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/20\n",
      "Train Loss: 0.0589\n",
      "Val Loss: 0.2488, Val Accuracy: 93.28%\n",
      "\n",
      "\n",
      "Started Training Loop = 18:05:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 364/364 [01:21<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Validaiton Loop = 18:06:44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 57/57 [00:08<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/20\n",
      "Train Loss: 0.0495\n",
      "Val Loss: 0.2546, Val Accuracy: 93.33%\n",
      "\n",
      "\n",
      "Started Training Loop = 18:06:52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 364/364 [01:18<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Validaiton Loop = 18:08:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 57/57 [00:08<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/20\n",
      "Train Loss: 0.0455\n",
      "Val Loss: 0.2373, Val Accuracy: 93.72%\n",
      "\n",
      "\n",
      "Started Training Loop = 18:08:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 364/364 [01:25<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Validaiton Loop = 18:09:44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 57/57 [00:09<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/20\n",
      "Train Loss: 0.0444\n",
      "Val Loss: 0.2559, Val Accuracy: 93.28%\n",
      "\n",
      "\n",
      "Started Training Loop = 18:09:53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 364/364 [01:29<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Validaiton Loop = 18:11:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 57/57 [00:08<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/20\n",
      "Train Loss: 0.0340\n",
      "Val Loss: 0.2533, Val Accuracy: 94.00%\n",
      "\n",
      "The model has been saved!\n",
      "Due to highest validation accuracy.\n",
      "\n",
      "Started Training Loop = 18:11:31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 364/364 [01:22<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Validaiton Loop = 18:12:53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 57/57 [00:08<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/20\n",
      "Train Loss: 0.0316\n",
      "Val Loss: 0.2417, Val Accuracy: 93.72%\n",
      "\n",
      "\n",
      "Started Training Loop = 18:13:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 364/364 [01:25<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Validaiton Loop = 18:14:27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 57/57 [00:08<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/20\n",
      "Train Loss: 0.0311\n",
      "Val Loss: 0.2704, Val Accuracy: 93.33%\n",
      "\n",
      "\n",
      "Started Training Loop = 18:14:35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 364/364 [01:22<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Validaiton Loop = 18:15:57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 57/57 [00:08<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/20\n",
      "Train Loss: 0.0252\n",
      "Val Loss: 0.2902, Val Accuracy: 93.28%\n",
      "\n",
      "\n",
      "Started Training Loop = 18:16:05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 364/364 [01:22<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Validaiton Loop = 18:17:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 57/57 [00:09<00:00,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/20\n",
      "Train Loss: 0.0273\n",
      "Val Loss: 0.3040, Val Accuracy: 93.22%\n",
      "\n",
      "Validation error grew by 50%, or validation accuracy dropped by 4%, so stopped training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochLoop(model, dataloaders, optimizer, criterion, device, class_names, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4929eccd-864d-4caf-ab9d-307b85195eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 108/108 [00:16<00:00,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for all classes: 89.13%\n",
      "Accuracy for class: Black is 78.42%, class size: 695\n",
      "Accuracy for class: Blue  is 92.91%, class size: 1086\n",
      "Accuracy for class: Green is 96.37%, class size: 799\n",
      "Accuracy for class: TTR   is 86.27%, class size: 852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "test_accuracy = predictALL(model, dataloaders['test'], device, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0646f7f-7a76-4a78-b705-f7bfebea86e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 108/108 [00:16<00:00,  6.44it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "test_predictions = np.array(predict(model, dataloaders['test'], device))\n",
    "\n",
    "cm = confusion_matrix(labels_test, test_predictions)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
